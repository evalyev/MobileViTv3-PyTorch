taskname: '+ MobileViTv2-1.0 DeepLabv3'
common:
  run_label: "train"
  accum_freq: 1
  accum_after_epoch: -1
  log_freq: 200
  auto_resume: false
  mixed_precision: true
  grad_clip: 10.0
dataset:
  root_train: "/mnt/vision_datasets/pascal_voc/VOCdevkit/"
  root_val: "/mnt/vision_datasets/pascal_voc/VOCdevkit/"
  name: "pascal"
  category: "segmentation"
  train_batch_size0: 32 # effective batch size is 128 (32 * 4 GPUs)
  val_batch_size0: 16
  eval_batch_size0: 1
  workers: 8
  persistent_workers: false
  pin_memory: false
  pascal:
    use_coco_data: true
    coco_root_dir: "/mnt/vision_datasets/coco_preprocess"
image_augmentation:
  random_crop:
    enable: true
    seg_class_max_ratio: 0.75
    pad_if_needed: true
    mask_fill: 255 # background idx is 255
  random_horizontal_flip:
    enable: true
  resize:
    enable: true
    size: [512, 512]
    interpolation: "bicubic"
  random_short_size_resize:
    enable: true
    interpolation: "bicubic"
    short_side_min: 256
    short_side_max: 768
    max_img_dim: 1024
  photo_metric_distort:
    enable: true
  random_rotate:
    enable: true
    angle: 10
    mask_fill: 255 # background idx is 255
  random_gaussian_noise:
    enable: true
sampler:
  name: "batch_sampler"
  bs:
    crop_size_width: 512
    crop_size_height: 512
loss:
  category: "segmentation"
  ignore_idx: 255
  segmentation:
    name: "cross_entropy"
    cross_entropy:
      aux_weight: 0.4
optim:
  name: "adamw"
  weight_decay: 0.05 #0.01
  no_decay_bn_filter_bias: true
  adamw:
    beta1: 0.9
    beta2: 0.999
scheduler:
  name: "cosine"
  is_iteration_based: false
  max_epochs: 50
  warmup_iterations: 500
  warmup_init_lr: 0.00005
  cosine:
    max_lr: 0.0005
    min_lr: 1.e-6
model:
  segmentation:
    name: "encoder_decoder"
    lr_multiplier: 1
    seg_head: "deeplabv3"
    output_stride: 16
    use_aux_head: true
    activation:
      name: "relu"
    deeplabv3:
      aspp_dropout: 0.1
      aspp_out_channels: 512
      aspp_rates: [ 6, 12, 18 ]
  classification:
    name: "mobilevit_v2"
    mitv2:
      width_multiplier: 1.0
      attn_norm_layer: "layer_norm_2d"
    activation:
      name: "swish"
  normalization:
    name: "sync_batch_norm"
    momentum: 0.1
  activation:
    name: "swish"
    inplace: false
  layer:
    global_pool: "mean"
    conv_init: "kaiming_uniform"
    linear_init: "normal"
ema:
  enable: true
  momentum: 0.0005
stats:
  val: [ "loss", "iou" ]
  train: [ "loss", "grad_norm" ]
  checkpoint_metric: "iou"
  checkpoint_metric_max: true