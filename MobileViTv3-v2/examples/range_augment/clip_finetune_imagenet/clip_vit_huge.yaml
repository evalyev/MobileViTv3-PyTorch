taskname: '+ CLIP-ViT-H/16 + FT-IN1k'
common:
  run_label: "train"
  log_freq: 500
  auto_resume: true
  mixed_precision: true
  mixed_precision_dtype: "bfloat16"
  save_all_checkpoints: true
dataset:
  root_train: "/mnt/imagenet/training"
  root_val: "/mnt/imagenet/validation"
  name: "imagenet"
  category: "classification"
  train_batch_size0: 64 # effective batch size is 512 (64 * 8 GPUs)
  val_batch_size0: 100
  eval_batch_size0: 100
  workers: 8
  persistent_workers: true
  pin_memory: true
image_augmentation:
  random_resized_crop:
    enable: true
    interpolation: "bilinear"
  random_horizontal_flip:
    enable: true
  resize:
    enable: true
    size: 232
    interpolation: "bilinear"
  center_crop:
    enable: true
    size: 224
sampler:
  name: "variable_batch_sampler"
  vbs:
    crop_size_width: 224
    crop_size_height: 224
    max_n_scales: 10
    min_crop_size_width: 128
    max_crop_size_width: 320
    min_crop_size_height: 128
    max_crop_size_height: 320
    check_scale: 16
loss:
  category: "classification"
  classification:
    name: "cross_entropy_with_na"
    label_smoothing: 0.1
  neural_aug:
    perceptual_metric: "psnr"
    target_value: [ 40, 20]
    curriculum_method: "cosine"
optim:
  name: "adamw"
  weight_decay: 0.05
  no_decay_bn_filter_bias: true
  adamw:
    beta1: 0.9
    beta2: 0.999
    eps: 1.e-6
scheduler:
  name: "cosine"
  is_iteration_based: false
  max_epochs: 10
  warmup_iterations: 500
  warmup_init_lr: 1.e-6
  cosine:
    max_lr: 0.00003
    min_lr: 1.e-6
model:
  resume_exclude_scopes: ["text_encoder", "logit_scale", "image_encoder.classifier.proj", "simple_fpn"]
  ignore_missing_scopes: ["classifier"]
  rename_scopes_map: [["image_encoder.", ""]]
  classification:
    name: "vit"
    pretrained: "https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/examples/range_augment/clip/clip_vit_huge_16.pt"
    gradient_checkpointing: true
    vit:
      mode: "huge"
      norm_layer: "layer_norm_fp32"
      checkpoint_segments: 4
    activation:
      name: "gelu"
  learn_augmentation:
    brightness: true
    contrast: true
    noise: true
    mode: "distribution"
  normalization:
    name: "batch_norm"
    momentum: 0.1
  activation:
    name: "gelu"
    inplace: true
  layer:
    global_pool: "mean"
    conv_init: "kaiming_uniform"
    linear_init: "trunc_normal"
    linear_init_std_dev: 0.02
ema:
  enable: true
  momentum: 0.0005
stats:
  val: [ "loss", "top1", "top5" ]
  train: ["loss"]
  checkpoint_metric: "top1.logits"
  checkpoint_metric_max: true